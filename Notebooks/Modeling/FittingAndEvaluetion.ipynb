{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8181952",
   "metadata": {},
   "source": [
    "# Fitting and Evaluation of Models   \n",
    "\n",
    "The purpose of this notebook is to try out different ML models on my data, tune their hyperparameters, and figure out which model best fits my data.   \n",
    "\n",
    "In this project, I will be using different types of linear models and some tree-based ensemble models.\n",
    "\n",
    "### Steps <a name = 'content'></a>   \n",
    "\n",
    "1. [Data Loading](#loading)  \n",
    "2. [Scoring Method](#scoring)    \n",
    "2. [Linear Regression](#lin_reg)    \n",
    "3. [Ridge Regression](#ridge)    \n",
    "4. [Lasso Regression](#lasso)   \n",
    "5. [Elastic Net](#el_net)   \n",
    "6. [Decision Tree](#tree)   \n",
    "7. [Random Forest](#forest)   \n",
    "8. [Extreme Gradient Boosting](#xgboost)   \n",
    "9. [Check and Save](#save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251390af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\samur\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\samur\\anaconda3\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\samur\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.core.common import random_state\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ecc0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.4\n",
      "1.22.4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10368/1498355099.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(sklearn.__version__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "#print(sklearn.__version__)\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30959cb6",
   "metadata": {},
   "source": [
    "# Data Loading <a name = 'loading'></a>  \n",
    "\n",
    "[Table of Content](#content)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4efb03",
   "metadata": {},
   "source": [
    "First of all, we load the training data prepared in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f108cee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132, 66)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../Data/train_data_processed.csv', index_col = 'Id')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b32be4",
   "metadata": {},
   "source": [
    "After that separate target variable from other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef97213",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()  \n",
    "y = X['SalePrice']\n",
    "X = X.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605eef12",
   "metadata": {},
   "source": [
    "For convenience, I will save all model results into a pd.Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de502b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samur\\AppData\\Local\\Temp/ipykernel_10368/1513092763.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  models_results = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "models_results = pd.Series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbec84",
   "metadata": {},
   "source": [
    "# Scoring Method <a name = 'scoring'></a>   \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82be53",
   "metadata": {},
   "source": [
    "A word or two must be said about the evaluation method I will be using in this notebook. I will not be using standard metrics such as 'mean_absolute_error' or 'root_mean_squared_error'. Instead, the Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price will be used. Why is that? Because the Kaggle competition from which the data is taken uses this metric. So I'm just repeating it.     \n",
    "\n",
    "Since the metric is not a standard metric I need to define a function that I will pass to the scoring parameter using cross validation.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6e3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My metric for cross validation\n",
    "def rmse_log(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.sqrt(mean_squared_error(np.log1p(y), np.log1p(y_pred)))\n",
    "\n",
    "# My metric for GridSearch\n",
    "def rmse_log_grid(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.log(y_true), np.log(y_pred)))\n",
    "\n",
    "custom_scorer = make_scorer(rmse_log_grid, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb6cd1",
   "metadata": {},
   "source": [
    "# Classical Linear Regression <a name = 'lin_reg'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566e48bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12149916987994222\n"
     ]
    }
   ],
   "source": [
    "# Define a model sample\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Get cross-validation score\n",
    "linear_regression_scores = cross_val_score(linear_regression,\n",
    "                         X,\n",
    "                         y,\n",
    "                         cv = 5,\n",
    "                         scoring = rmse_log)\n",
    "\n",
    "print(linear_regression_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a155946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result\n",
    "models_results['linear_regression'] = linear_regression_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae86b1f",
   "metadata": {},
   "source": [
    "# Ridge Regression <a name = 'ridge'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9117472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of λ:  {'alpha': 1, 'random_state': 0}\n",
      "Best score:  -0.1187338322310516\n"
     ]
    }
   ],
   "source": [
    "# Create a model sample\n",
    "ridge_sample = Ridge()\n",
    "\n",
    "# Set the search area for GridSearch.\n",
    "ridge_hyper_params = {'alpha': range(1, 100, 5), 'random_state': [0]}\n",
    "\n",
    "# Create a GridSearch sample\n",
    "ridge_regression = GridSearchCV(ridge_sample, ridge_hyper_params, scoring = custom_scorer, cv = 10)\n",
    "\n",
    "# Fit the model\n",
    "ridge_regression.fit(X, y)\n",
    "\n",
    "print('Best value of λ: ', ridge_regression.best_params_)\n",
    "print('Best score: ', ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb7a1a",
   "metadata": {},
   "source": [
    "Okay, we've roughly figured out in which range the best alpha value lies. Let's try to get a more accurate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab91f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of λ:  {'alpha': 2.641025641025641, 'random_state': 0}\n",
      "Best score:  -0.11852401419682393\n"
     ]
    }
   ],
   "source": [
    "ridge_hyper_params = {'alpha': np.linspace(1, 5, 40), 'random_state': [0]}   \n",
    "ridge_regression = GridSearchCV(ridge_sample, ridge_hyper_params, scoring = custom_scorer, cv = 10)\n",
    "ridge_regression.fit(X, y)\n",
    "\n",
    "print('Best value of λ: ', ridge_regression.best_params_)\n",
    "print('Best score: ', ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb35699",
   "metadata": {},
   "source": [
    "Okay, now we'll save the ridge regression model with best value of alpha.    \n",
    "\n",
    "**NOTE!** The process of finding the best hyperparameters is the same for each model. I don't want to overload this notebook with similar blocks of code, so I will leave only the \"best attempts\" for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45dbffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['ridge_regression'] = ridge_regression.best_score_\n",
    "\n",
    "ridge_best_params = ridge_regression.best_params_\n",
    "ridge_regression = Ridge(**ridge_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119caeb",
   "metadata": {},
   "source": [
    "# Lasso Regression <a name = 'lasso'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b24b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't want to overload the output of the LASSO regression and Elastic Net\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1267327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  {'alpha': 41, 'random_state': 0}\n",
      "score:  -0.11749945302004305\n"
     ]
    }
   ],
   "source": [
    "lasso_sample = Lasso()\n",
    "lasso_hyper_params = {'alpha': range (30, 45), 'random_state': [0]}\n",
    "lasso_regression = GridSearchCV(lasso_sample, lasso_hyper_params, scoring = custom_scorer, cv = 10)\n",
    "lasso_regression.fit(X, y)\n",
    "\n",
    "print('best alpha: ', lasso_regression.best_params_)\n",
    "print('score: ', lasso_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7213a61",
   "metadata": {},
   "source": [
    "Save the model with best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4caf14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['lasso_regression'] = lasso_regression.best_score_\n",
    "\n",
    "lasso_best_params = lasso_regression.best_params_\n",
    "lasso_regression = Lasso(**lasso_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd174806",
   "metadata": {},
   "source": [
    "# Elastic Net <a name = 'el_net'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a4437",
   "metadata": {},
   "source": [
    "Do the same steps as with the Ridge and Lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8330f6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha and l1_ratio:  {'alpha': 41, 'l1_ratio': 1.0, 'random_state': 0}\n",
      "score:  -0.11749945302004305\n"
     ]
    }
   ],
   "source": [
    "elastic_net_sample = ElasticNet()\n",
    "elnet_hyper_params = {'alpha': range(35, 45), 'l1_ratio': np.linspace(0.99, 1, 10), 'random_state': [0]}\n",
    "elastic_net = GridSearchCV(elastic_net_sample, elnet_hyper_params, scoring = custom_scorer, cv = 10)\n",
    "elastic_net.fit(X, y)\n",
    "\n",
    "print('best alpha and l1_ratio: ', elastic_net.best_params_)\n",
    "print('score: ', elastic_net.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5c466",
   "metadata": {},
   "source": [
    "Lasso regression seems to be the best fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1bedd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['elastic_net'] = elastic_net.best_score_\n",
    "\n",
    "elnet_best_params = elastic_net.best_params_\n",
    "elastic_net = ElasticNet(**elnet_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2524c77",
   "metadata": {},
   "source": [
    "# DecisionTree <a name = 'tree'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fe651",
   "metadata": {},
   "source": [
    "All the same steps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee72ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT params:  {'ccp_alpha': 0.0, 'max_depth': 6, 'max_features': 35, 'min_impurity_decrease': 0, 'min_samples_leaf': 6, 'min_samples_split': 2, 'random_state': 0}\n",
      "Best score:  -0.1371179620163833\n"
     ]
    }
   ],
   "source": [
    "decision_tree_sample = DecisionTreeRegressor()\n",
    "decision_tree_hyper_params = {'max_depth': range(5, 8),\n",
    "                              'min_samples_split': [2, 3],\n",
    "                              'min_samples_leaf': [6, 7 ,8],\n",
    "                              'max_features': range(32, 38),\n",
    "                              'random_state': [0],\n",
    "                              'min_impurity_decrease': range(0, 2),\n",
    "                              'ccp_alpha': np.linspace(0, 1, 3)\n",
    "                             }\n",
    "decision_tree_regressor = GridSearchCV(decision_tree_sample, decision_tree_hyper_params, \n",
    "                                       scoring = custom_scorer, cv = 10)\n",
    "decision_tree_regressor.fit(X, y)\n",
    "\n",
    "print('Best DT params: ', decision_tree_regressor.best_params_)\n",
    "print('Best score: ', decision_tree_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa504f54",
   "metadata": {},
   "source": [
    "The model does not seem to suffer from overfitting, since best value of `min_impurity_decrease` and `ccp_alpha` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2db82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['decision_tree_regressor'] = decision_tree_regressor.best_score_\n",
    "\n",
    "decision_tree_best_params = decision_tree_regressor.best_params_\n",
    "decision_tree_regressor = DecisionTreeRegressor(**decision_tree_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052ee6a",
   "metadata": {},
   "source": [
    "# Random Forest <a name = 'forest'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b30eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 27, 'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1150, 'n_jobs': -1, 'random_state': 0}\n",
      "Best score:  -0.11115767045055536\n"
     ]
    }
   ],
   "source": [
    "random_forest_sample = RandomForestRegressor()\n",
    "random_forest_hyper_params = {'n_estimators': [1150],\n",
    "                              'max_depth': [27], # 30 14 - 0.11081\n",
    "                              'min_samples_split': [3],\n",
    "                              'min_samples_leaf': [1],\n",
    "                              'max_features': [12],\n",
    "                              'random_state': [0],\n",
    "                              'n_jobs': [-1]\n",
    "                             }\n",
    "random_forest_regressor = GridSearchCV(random_forest_sample, random_forest_hyper_params, \n",
    "                                       scoring = custom_scorer, cv = 5)\n",
    "random_forest_regressor.fit(X, y)\n",
    "\n",
    "print('Best parameters: ', random_forest_regressor.best_params_)\n",
    "print('Best score: ', random_forest_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a36d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['random_forest_regressor'] = random_forest_regressor.best_score_\n",
    "\n",
    "random_forest_best_params = random_forest_regressor.best_params_\n",
    "random_forest_regressor = RandomForestRegressor(**random_forest_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56057cd",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting <a name = 'xgboost'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81c1fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to use eval_set in selecting the best values for n_estimators and learning_rate\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "18d5715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samur\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for n_estimators:  38\n",
      "XGBRegressor score:  0.11799976470681713\n"
     ]
    }
   ],
   "source": [
    "# Find the best values for n_estimators and learning_rate\n",
    "\n",
    "# The best learning_rate was found through experimentation and multiple code executions. Here you can only see the result\n",
    "xgb_regressor_presearch = XGBRegressor(n_estimators = 1000, learning_rate = 0.25, random_state = 0) \n",
    "xgb_regressor_presearch.fit(X_train, y_train,\n",
    "                 early_stopping_rounds = 100,\n",
    "                 eval_set = [(X_valid, y_valid)],\n",
    "                 verbose = False)\n",
    "\n",
    "print(\"Best value for n_estimators: \", xgb_regressor_presearch.best_iteration)\n",
    "\n",
    "xgb_best_iteration = xgb_regressor_presearch.best_iteration\n",
    "xgb_regressor_ = XGBRegressor(n_estimators = xgb_best_iteration)\n",
    "\n",
    "\n",
    "# Get neg_mean_absolute_error for XGBRegressor with this parameters\n",
    "scores = cross_val_score(xgb_regressor_presearch,\n",
    "                         X, y,\n",
    "                         cv = 10,\n",
    "                         scoring = rmse_log\n",
    "                        )\n",
    "print('XGBRegressor score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f147012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.25, 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 38, 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1}\n",
      "Best score:  -0.11238739375225304\n"
     ]
    }
   ],
   "source": [
    "# Find the best values for all other parameters using GridSearchCV\n",
    "\n",
    "# All the values were found through experimentation and multiple code executions. Here you can only see the result\n",
    "xgb_regressor_sample = XGBRegressor()\n",
    "xgb_hyper_params = {'n_estimators': [xgb_best_iteration],\n",
    "                    'learning_rate': [0.25],\n",
    "                    'max_depth': [2, 3], \n",
    "                    'min_child_weight': [6, 7, 8],  \n",
    "                    'gamma': [0],\n",
    "                    'subsample': [1],\n",
    "                    'colsample_bytree': [1],\n",
    "                    'reg_alpha': [0],\n",
    "                    'reg_lambda': [1],\n",
    "                    'random_state': [0]\n",
    "                   }\n",
    "\n",
    "xgb_regressor = GridSearchCV(xgb_regressor_sample, xgb_hyper_params, scoring = custom_scorer, cv = 10)\n",
    "xgb_regressor.fit(X, y)\n",
    "\n",
    "print('Best parameters: ', xgb_regressor.best_params_)\n",
    "print('Best score: ', xgb_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4aa495e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['xgb_regressor'] = xgb_regressor.best_score_\n",
    "\n",
    "xgb_best_params = xgb_regressor.best_params_\n",
    "xgb_regressor = XGBRegressor(**xgb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d18e6",
   "metadata": {},
   "source": [
    "# Check and Save <a name = 'save'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc7305",
   "metadata": {},
   "source": [
    "Check all the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd3a1e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_regression          0.121499\n",
       "random_forest_regressor   -0.111158\n",
       "xgb_regressor             -0.112387\n",
       "elastic_net               -0.117499\n",
       "lasso_regression          -0.117499\n",
       "ridge_regression          -0.118524\n",
       "decision_tree_regressor   -0.137118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = models_results.sort_values(ascending = False)\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca554d0a",
   "metadata": {},
   "source": [
    "Create a DataFrame with all the model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "540c26b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinearRegression(),\n",
       " Ridge(alpha=2.641025641025641, random_state=0),\n",
       " Lasso(alpha=41, random_state=0),\n",
       " ElasticNet(alpha=41, l1_ratio=1.0, random_state=0),\n",
       " DecisionTreeRegressor(max_depth=6, max_features=35, min_impurity_decrease=0,\n",
       "                       min_samples_leaf=6, random_state=0),\n",
       " RandomForestRegressor(max_depth=27, max_features=12, min_samples_split=3,\n",
       "                       n_estimators=1150, n_jobs=-1, random_state=0),\n",
       " XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.25, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=38,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=0, ...)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [linear_regression, ridge_regression, lasso_regression, elastic_net, decision_tree_regressor, \n",
    "          random_forest_regressor, xgb_regressor]\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e3065",
   "metadata": {},
   "source": [
    "The model parameters are saved correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7959336",
   "metadata": {},
   "source": [
    "Save scores and model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b06ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'models' (list)\n",
      "Stored 'models_results' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store models\n",
    "%store models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5baead",
   "metadata": {},
   "source": [
    "And we are done here. Let's try our model on validation data and see the real results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
