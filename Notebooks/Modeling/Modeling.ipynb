{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8181952",
   "metadata": {},
   "source": [
    "## Table of Content <a name = 'content'></a>   \n",
    "\n",
    "1. [Data Loading](#loading)  \n",
    "2. [Linear Regression](#lin_reg)    \n",
    "3. [Ridge Regression](#ridge)    \n",
    "4. [Lasso Regression](#lasso)   \n",
    "5. [Elastic Net](#el_net)   \n",
    "6. [Decision Tree](#tree)   \n",
    "7. [Random Forest](#forest)   \n",
    "8. [Extreme Gradient Boosting](#xgboost)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "251390af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\samur\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\samur\\anaconda3\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\samur\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.core.common import random_state\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30959cb6",
   "metadata": {},
   "source": [
    "# Data Loading <a name = 'loading'></a>  \n",
    "\n",
    "[Table of Content](#content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f108cee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>Exterior1st_BrkFace</th>\n",
       "      <th>Exterior1st_CemntBd</th>\n",
       "      <th>Exterior1st_HdBoard</th>\n",
       "      <th>Exterior1st_MetalSd</th>\n",
       "      <th>Exterior1st_Plywood</th>\n",
       "      <th>Exterior1st_Stucco</th>\n",
       "      <th>Exterior1st_VinylSd</th>\n",
       "      <th>Exterior1st_Wd Sdng</th>\n",
       "      <th>Exterior1st_WdShing</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>548</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>8450</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>460</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1786</td>\n",
       "      <td>608</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>11250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1717</td>\n",
       "      <td>642</td>\n",
       "      <td>1915</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>9550</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>2198</td>\n",
       "      <td>836</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1053</td>\n",
       "      <td>1</td>\n",
       "      <td>14260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    OverallQual  GrLivArea  GarageArea  YearBuilt  TotalBsmtSF  FullBath  \\\n",
       "Id                                                                         \n",
       "1             7       1710         548       2003          856         2   \n",
       "2             6       1262         460       1976         1262         2   \n",
       "3             7       1786         608       2001          920         2   \n",
       "4             7       1717         642       1915          756         1   \n",
       "5             8       2198         836       2000         1145         2   \n",
       "\n",
       "    YearRemodAdd  2ndFlrSF  Fireplaces  LotArea  ...  Exterior1st_BrkFace  \\\n",
       "Id                                               ...                        \n",
       "1           2003       854           0     8450  ...                    0   \n",
       "2           1976         0           1     9600  ...                    0   \n",
       "3           2002       866           1    11250  ...                    0   \n",
       "4           1970       756           1     9550  ...                    0   \n",
       "5           2000      1053           1    14260  ...                    0   \n",
       "\n",
       "    Exterior1st_CemntBd  Exterior1st_HdBoard  Exterior1st_MetalSd  \\\n",
       "Id                                                                  \n",
       "1                     0                    0                    0   \n",
       "2                     0                    0                    1   \n",
       "3                     0                    0                    0   \n",
       "4                     0                    0                    0   \n",
       "5                     0                    0                    0   \n",
       "\n",
       "    Exterior1st_Plywood  Exterior1st_Stucco  Exterior1st_VinylSd  \\\n",
       "Id                                                                 \n",
       "1                     0                   0                    1   \n",
       "2                     0                   0                    0   \n",
       "3                     0                   0                    1   \n",
       "4                     0                   0                    0   \n",
       "5                     0                   0                    1   \n",
       "\n",
       "    Exterior1st_Wd Sdng  Exterior1st_WdShing  SalePrice  \n",
       "Id                                                       \n",
       "1                     0                    0     208500  \n",
       "2                     0                    0     181500  \n",
       "3                     0                    0     223500  \n",
       "4                     1                    0     140000  \n",
       "5                     0                    0     250000  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../Data/data_processed.csv', index_col = 'Id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ef97213",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()  \n",
    "\n",
    "y = X['SalePrice']\n",
    "\n",
    "X = X.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de502b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samur\\AppData\\Local\\Temp/ipykernel_584/1781800705.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  models_results = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for storing models results\n",
    "models_results = pd.Series()\n",
    "\n",
    "# List for storing all models\n",
    "all_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb6cd1",
   "metadata": {},
   "source": [
    "# Classical Linear Regression <a name = 'lin_reg'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "566e48bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14231.924375192946\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "linear_regression_scores = cross_val_score(linear_regression,\n",
    "                         X,\n",
    "                         y,\n",
    "                         cv = 5,\n",
    "                         scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "print(linear_regression_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a155946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['linear_regression'] = linear_regression_scores.mean()\n",
    "\n",
    "all_models.append(linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae86b1f",
   "metadata": {},
   "source": [
    "# Ridge Regression <a name = 'ridge'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a9117472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of λ:  {'alpha': 6, 'random_state': 0}\n",
      "Best score:  -14054.142695898288\n"
     ]
    }
   ],
   "source": [
    "ridge_sample = Ridge()\n",
    "ridge_hyper_params = {'alpha': range(1, 100, 5), 'random_state': [0]}\n",
    "ridge_regression = GridSearchCV(ridge_sample, ridge_hyper_params, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "ridge_regression.fit(X, y)\n",
    "\n",
    "print('Best value of λ: ', ridge_regression.best_params_)\n",
    "print('Best score: ', ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb7a1a",
   "metadata": {},
   "source": [
    "Okay, we've roughly figured out in which range the best alpha value lies. Let's try to get a more accurate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab91f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of λ:  {'alpha': 3.076923076923077, 'random_state': 0}\n",
      "Best score:  -14039.208670160035\n"
     ]
    }
   ],
   "source": [
    "ridge_hyper_params = {'alpha': np.linspace(1, 10, 40), 'random_state': [0]}\n",
    "ridge_regression = GridSearchCV(ridge_sample, ridge_hyper_params, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "ridge_regression.fit(X, y)\n",
    "\n",
    "print('Best value of λ: ', ridge_regression.best_params_)\n",
    "print('Best score: ', ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb35699",
   "metadata": {},
   "source": [
    "Okay, now we'll save the ridge regression model with best value of alpha.    \n",
    "\n",
    "**NOTE!** The process of finding the best hyperparameters is the same for each model. I don't want to overload this notebook with similar blocks of code, so I will leave only the \"best attempts\" for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "45dbffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['ridge_regression'] = ridge_regression.best_score_\n",
    "\n",
    "ridge_best_params = ridge_regression.best_params_\n",
    "\n",
    "ridge_regression = Ridge(**ridge_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "239e7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(ridge_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119caeb",
   "metadata": {},
   "source": [
    "# Lasso Regression <a name = 'lasso'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5b24b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't want to overload the output of the LASSO regression and Elastic Net\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1267327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  {'alpha': 52, 'random_state': 0}\n",
      "score:  -13943.969522193185\n"
     ]
    }
   ],
   "source": [
    "lasso_sample = Lasso()\n",
    "lasso_hyper_params = {'alpha': range (45, 60), 'random_state': [0]}\n",
    "lasso_regression = GridSearchCV(lasso_sample, lasso_hyper_params, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "lasso_regression.fit(X, y)\n",
    "\n",
    "print('best alpha: ', lasso_regression.best_params_)\n",
    "print('score: ', lasso_regression.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7213a61",
   "metadata": {},
   "source": [
    "Save the model with best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4caf14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['lasso_regression'] = lasso_regression.best_score_\n",
    "\n",
    "lasso_best_params = lasso_regression.best_params_\n",
    "\n",
    "lasso_regression = Lasso(**lasso_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "30477a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(lasso_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd174806",
   "metadata": {},
   "source": [
    "# Elastic Net <a name = 'el_net'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a4437",
   "metadata": {},
   "source": [
    "Do the same steps as with the Ridge and Lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8330f6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha and l1_ratio:  {'alpha': 52, 'l1_ratio': 1.0, 'random_state': 0}\n",
      "score:  -13943.969522193185\n"
     ]
    }
   ],
   "source": [
    "elastic_net_sample = ElasticNet()\n",
    "elnet_hyper_params = {'alpha': range(45, 60), 'l1_ratio': np.linspace(0.99, 1, 5), 'random_state': [0]}\n",
    "elastic_net = GridSearchCV(elastic_net_sample, elnet_hyper_params, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "elastic_net.fit(X, y)\n",
    "\n",
    "print('best alpha and l1_ratio: ', elastic_net.best_params_)\n",
    "print('score: ', elastic_net.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5c466",
   "metadata": {},
   "source": [
    "Lasso regression seems to be the best fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1bedd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['elastic_net'] = elastic_net.best_score_\n",
    "\n",
    "elnet_best_params = elastic_net.best_params_\n",
    "\n",
    "elastic_net = ElasticNet(**elnet_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b07cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(elastic_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2524c77",
   "metadata": {},
   "source": [
    "# DecisionTree <a name = 'tree'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee72ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT params:  {'ccp_alpha': 0.0, 'max_depth': 8, 'max_features': 41, 'min_impurity_decrease': 0, 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 0}\n",
      "Best score:  -16727.753705152823\n"
     ]
    }
   ],
   "source": [
    "decision_tree_sample = DecisionTreeRegressor()\n",
    "decision_tree_hyper_params = {'max_depth': [8],\n",
    "                              'min_samples_split': range(2, 4),\n",
    "                              'min_samples_leaf': range(2, 5),\n",
    "                              'max_features': range(40, 42),\n",
    "                              'random_state': [0],\n",
    "                              'min_impurity_decrease': range(0, 2),\n",
    "                              'ccp_alpha': np.linspace(0, 1, 3)\n",
    "                             }\n",
    "decision_tree_regressor = GridSearchCV(decision_tree_sample, decision_tree_hyper_params, \n",
    "                                       scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "decision_tree_regressor.fit(X, y)\n",
    "\n",
    "print('Best DT params: ', decision_tree_regressor.best_params_)\n",
    "print('Best score: ', decision_tree_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa504f54",
   "metadata": {},
   "source": [
    "The model does not seem to suffer from overfitting, since best value of `min_impurity_decrease` and `ccp_alpha` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a2db82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['decision_tree_regressor'] = decision_tree_regressor.best_score_\n",
    "\n",
    "decision_tree_best_params = decision_tree_regressor.best_params_\n",
    "\n",
    "decision_tree_regressor = DecisionTreeRegressor(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c83a9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(decision_tree_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052ee6a",
   "metadata": {},
   "source": [
    "# Random Forest <a name = 'forest'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3b30eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 31, 'max_features': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1100, 'n_jobs': -1, 'random_state': 0}\n",
      "Best score:  -12596.608348303494\n"
     ]
    }
   ],
   "source": [
    "random_forest_sample = RandomForestRegressor()\n",
    "random_forest_hyper_params = {'n_estimators': [1100],\n",
    "                              'max_depth': [31],\n",
    "                              'min_samples_split': [3],\n",
    "                              'min_samples_leaf': [1],\n",
    "                              'max_features': [15],\n",
    "                              'random_state': [0],\n",
    "                              'n_jobs': [-1]\n",
    "                             }\n",
    "random_forest_regressor = GridSearchCV(random_forest_sample, random_forest_hyper_params, \n",
    "                                       scoring = 'neg_mean_absolute_error', cv = 5)\n",
    "random_forest_regressor.fit(X, y)\n",
    "\n",
    "print('Best parameters: ', random_forest_regressor.best_params_)\n",
    "print('Best score: ', random_forest_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a36d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['random_forest_regressor'] = random_forest_regressor.best_score_\n",
    "\n",
    "random_forest_best_params = random_forest_regressor.best_params_\n",
    "\n",
    "random_forest_regressor = RandomForestRegressor(**random_forest_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2ef58f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(random_forest_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f4c2d",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting <a name = 'xgboost'></a>  \n",
    "\n",
    "[Table of Content](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "58228b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to use eval_set in selecting the best values for n_estimators and learning_rate\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "18d5715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samur\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for n_estimators:  17\n",
      "XGBRegressor score:  -13760.97912742829\n"
     ]
    }
   ],
   "source": [
    "# Find the best values for n_estimators and learning_rate\n",
    "\n",
    "# The best learning_rate was found through experimentation and multiple code executions. Here you can only see the result\n",
    "xgb_regressor_presearch = XGBRegressor(n_estimators = 1000, learning_rate = 0.25, random_state = 0) \n",
    "xgb_regressor_presearch.fit(X_train, y_train,\n",
    "                 early_stopping_rounds = 100,\n",
    "                 eval_set = [(X_valid, y_valid)],\n",
    "                 verbose = False)\n",
    "\n",
    "print(\"Best value for n_estimators: \", xgb_regressor_presearch.best_iteration)\n",
    "\n",
    "best_iteration = xgb_regressor_presearch.best_iteration\n",
    "xgb_regressor_ = XGBRegressor(n_estimators = best_iteration)\n",
    "\n",
    "\n",
    "# Get neg_mean_absolute_error for XGBRegressor with this parameters\n",
    "scores = cross_val_score(xgb_regressor_presearch,\n",
    "                         X, y,\n",
    "                         cv = 10,\n",
    "                         scoring = 'neg_mean_absolute_error'\n",
    "                        )\n",
    "print('XGBRegressor score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f147012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.25, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 17, 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1}\n",
      "Best score:  -12880.093265312064\n"
     ]
    }
   ],
   "source": [
    "# Find the best values for all other parameters using GridSearchCV\n",
    "\n",
    "\n",
    "# All the values were found through experimentation and multiple code executions. Here you can only see the result\n",
    "xgb_regressor_sample = XGBRegressor()\n",
    "xgb_hyper_params = {'n_estimators': [best_iteration],\n",
    "                    'learning_rate': [0.25],\n",
    "                    'max_depth': [4], \n",
    "                    'min_child_weight': [7],  \n",
    "                    'gamma': [0],\n",
    "                    'subsample': [1],\n",
    "                    'colsample_bytree': [1],\n",
    "                    'reg_alpha': [0],\n",
    "                    'reg_lambda': [1],\n",
    "                    'random_state': [0]\n",
    "                   }\n",
    "\n",
    "xgb_regressor = GridSearchCV(xgb_regressor_sample, xgb_hyper_params, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "xgb_regressor.fit(X, y)\n",
    "\n",
    "print('Best parameters: ', xgb_regressor.best_params_)\n",
    "print('Best score: ', xgb_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "44427aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results['xgb_regressor'] = xgb_regressor.best_score_\n",
    "\n",
    "xgb_best_params = xgb_regressor.best_params_\n",
    "\n",
    "xgb_regressor = XGBRegressor(**xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "125617f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.append(xgb_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "be053f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_forest_regressor   -12596.608348\n",
       "xgb_regressor             -12880.093265\n",
       "lasso_regression          -13943.969522\n",
       "elastic_net               -13943.969522\n",
       "ridge_regression          -14039.208670\n",
       "linear_regression         -14231.924375\n",
       "decision_tree_regressor   -16727.753705\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0dc1e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinearRegression(),\n",
       " Ridge(alpha={'alpha': 3.076923076923077, 'random_state': 0}),\n",
       " Lasso(alpha={'alpha': 52, 'random_state': 0}),\n",
       " ElasticNet(alpha={'alpha': 52, 'l1_ratio': 1.0, 'random_state': 0}),\n",
       " DecisionTreeRegressor(max_depth=8, max_features=41, min_impurity_decrease=0,\n",
       "                       min_samples_leaf=4, random_state=0),\n",
       " RandomForestRegressor(n_estimators={'max_depth': 31, 'max_features': 15,\n",
       "                                     'min_samples_leaf': 1,\n",
       "                                     'min_samples_split': 3,\n",
       "                                     'n_estimators': 1100, 'n_jobs': -1,\n",
       "                                     'random_state': 0}),\n",
       " XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.25, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=17,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=0, ...)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f579267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()  score:  -14127.447120266355\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'alpha' parameter of Ridge must be a float in the range [0.0, inf) or an instance of 'numpy.ndarray'. Got {'alpha': 3.076923076923077, 'random_state': 0} instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_584/2842576319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     scores = cross_val_score(model,\n\u001b[0m\u001b[0;32m      3\u001b[0m                             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             cv = 10)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                     )\n\u001b[0;32m    213\u001b[0m                 ):\n\u001b[1;32m--> 214\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m# For callable scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             )\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n    estimator._validate_params()\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n    validate_parameter_constraints(\n  File \"C:\\Users\\samur\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'alpha' parameter of Ridge must be a float in the range [0.0, inf) or an instance of 'numpy.ndarray'. Got {'alpha': 3.076923076923077, 'random_state': 0} instead.\n"
     ]
    }
   ],
   "source": [
    "for model in all_models:\n",
    "    scores = cross_val_score(model,\n",
    "                            X, y,\n",
    "                            scoring = 'neg_mean_absolute_error',\n",
    "                            cv = 10)\n",
    "    print(model, ' score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cdef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
